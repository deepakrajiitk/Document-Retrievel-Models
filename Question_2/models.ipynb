{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee027a19",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9168fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be689ab",
   "metadata": {},
   "source": [
    "### Importing relevant data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7cb460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open(sys.path[0]+'/../Question_1/pickle_data', 'rb')     \n",
    "database = pickle.load(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e655e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = database['main_dict']\n",
    "norm_list = database['norm_list']\n",
    "docs_nwords_list = database['docs_nwords_list']\n",
    "n_docs = database['n_docs']\n",
    "file_index = database['file_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1783076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20e67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8df3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanQuery(query):\n",
    "    # applying same operations on query as applied on each document \n",
    "    query = re.sub('[^a-zA-Z0-9]',' ',query)\n",
    "    query = query.lower()\n",
    "    query = query.split()\n",
    "    query = np.array([stemmer.stem(word) for word in query if not word in set(stopwords.words('english'))])\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd3e2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function return top ten relevant documents and their relevance status\n",
    "def find_top_relevant(score, n):\n",
    "#     getting top 10 relevant documents id\n",
    "    score_index = np.argsort(score)[::-1][:n]\n",
    "#     getting\n",
    "    relevance = [0 if score[i]==0 else 1 for i in score_index]\n",
    "    relevant_files = list(map(file_index.__getitem__, score_index))\n",
    "    return relevant_files, relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b05888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates cosine similarities between document vectors and query vector\n",
    "def find_cosine_sim(n_docs, query_vector, doc_vectors):\n",
    "    cosine_sims = []\n",
    "    for i in range(n_docs):\n",
    "        dot = np.dot(query_vector, doc_vectors[i])\n",
    "        query_norm = np.linalg.norm(query_vector)\n",
    "        doc_norm = norm_list[i]\n",
    "        cosine_sims.append(dot/(query_norm*doc_norm))\n",
    "    return cosine_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47971f",
   "metadata": {},
   "source": [
    "### Boolean Retreival Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64244f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned query must be sent to this model\n",
    "def brModel(query, main_dict, n_docs):\n",
    "    boolean_dict = {} # dictionary storing boolean vector of each word\n",
    "    # format => {word : list}\n",
    "    for word in np.unique(query):\n",
    "        bit_vector = [0 for i in range(n_docs)]\n",
    "        if word in main_dict.keys():\n",
    "            word_dict = main_dict[word]\n",
    "            for key in word_dict.keys():\n",
    "                bit_vector[key] = 1\n",
    "        boolean_dict[word] = bit_vector\n",
    "\n",
    "    # applying '&' operations on each boolean vector\n",
    "    ans = [1 for i in range(n_docs)]\n",
    "    for value in boolean_dict.values():\n",
    "        for i in range(n_docs):\n",
    "            ans[i] = ans[i] & value[i]\n",
    "    return find_top_relevant(ans,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da845a0d",
   "metadata": {},
   "source": [
    "### Implementing TFIDF family system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209bbb9",
   "metadata": {},
   "source": [
    "Formulae used:\n",
    "\\begin{align*}\n",
    "& TF = \\text{no of time a word occurs in a document} \\\\\n",
    "& idf = \\ln\\frac{N+1}{df_t+1} \\\\\n",
    "& tfidf = tf*idf \\\\\n",
    "where, \\\\\n",
    "& tf = \\text{term frequency} \\\\\n",
    "& idf = \\text{ document frequency} \\\\\n",
    "& N = \\text{total no of documents} \\\\\n",
    "& df_t = \\text{no of document in which a particular term is presnt}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "800176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned query must be sent to this model\n",
    "def tfidf(n_docs, docs_nwords_list, main_dict, query):\n",
    "    # finding document vectors\n",
    "    tfidf_dict = {} # dictionary which stores tfidf of each document\n",
    "    doc_vectors = [] \n",
    "    for i in range(n_docs):\n",
    "        n_words = docs_nwords_list[i]\n",
    "        vector = []\n",
    "        for word in np.unique(query):\n",
    "            if word in main_dict.keys() and i in main_dict[word].keys():\n",
    "#                 tf = main_dict[word][i]/n_words\n",
    "                tf = main_dict[word][i]\n",
    "                idf = math.log((n_docs+1)/(len(main_dict[word].keys())+1))\n",
    "                tf_idf = tf*idf\n",
    "                vector.append(tf_idf)\n",
    "            else:\n",
    "                vector.append(0)\n",
    "        doc_vectors.append(vector)\n",
    "    word_freq_query_dict = Counter(query)\n",
    "    # finding query vector\n",
    "    query_vector = []\n",
    "    # remember np.unique return result in alphabetical order\n",
    "    for word in np.unique(query):\n",
    "        if word in main_dict.keys():\n",
    "#             tf = word_freq_query_dict[word]/len(query)\n",
    "            tf = word_freq_query_dict[word]\n",
    "            idf = math.log((n_docs+1)/(len(main_dict[word].keys())+1))\n",
    "            tf_idf = tf*idf\n",
    "            query_vector.append(tf_idf)\n",
    "        else:\n",
    "            query_vector.append(0)\n",
    "    scores = find_cosine_sim(n_docs, query_vector, doc_vectors)\n",
    "    return find_top_relevant(scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da45066",
   "metadata": {},
   "source": [
    "### Implementing BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2ac15",
   "metadata": {},
   "source": [
    "Formulae used \n",
    "$$ \\sum_{\\forall t \\in q} (1 + \\ln (\\frac{n - df_t + 0.5}{df_t + 0.5})) . \\frac{(k1+1).(tf_d)}{tf_d + k1 * (1-b+b*\\frac{L_d}{L_{avg}})}$$\n",
    "where,\n",
    "$$ n - \\text{total documents} $$\n",
    "$$ df_t - \\text{total no of ducuments in which term is present} $$\n",
    "$$ tf_d - \\text{frequency of term in a document d} $$\n",
    "$$ k1, b - \\text{tuning parameters} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e996d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean query must be sent to this model\n",
    "def BM25(b, k1, main_dict, docs_nwords_list, n_docs, query):\n",
    "    score = []\n",
    "    L_avg = sum(docs_nwords_list)/len(docs_nwords_list) #avg length of document\n",
    "    for i in range(n_docs):\n",
    "        L_d = docs_nwords_list[i] # length of document\n",
    "        ans = 0\n",
    "        for word in np.unique(query):\n",
    "            if word in main_dict.keys() and i in main_dict[word]:\n",
    "                df_t = len(main_dict[word].keys())+1\n",
    "                tf_d = main_dict[word][i]\n",
    "                idf = math.log(1 + (n_docs - df_t + 0.5 )/(df_t+0.5))\n",
    "                first_term = (k1+1)*tf_d\n",
    "                second_term = tf_d + k1*(1-b+b*(L_d/L_avg))\n",
    "                temp = idf * (first_term/second_term)\n",
    "                ans += temp\n",
    "        score.append(ans)\n",
    "        top_relevant = find_top_relevant(score, 10)\n",
    "    return top_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0eb0f",
   "metadata": {},
   "source": [
    "### Reading query file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a04ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_fname = \"queries.txt\" # reading file name from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e45abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv(sys.path[0]+'/../'+queries_fname, sep=\"\\t\")\n",
    "    queryIds = df['QueryId'].values\n",
    "    queries = df['Query'].values\n",
    "except:\n",
    "    df = pd.read_csv(sys.path[0]+'/../'+queries_fname, sep=\"\\t\",header=None)\n",
    "    queryIds = df. iloc[:, 0].values\n",
    "    queries = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96829583",
   "metadata": {},
   "source": [
    "### Running set of queries on different algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6bc7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting result from all the models for given queries\n"
     ]
    }
   ],
   "source": [
    "BRM_result = []\n",
    "TFIDF_result = []\n",
    "BM25_result = []\n",
    "\n",
    "print(\"Getting result from all the models for given queries\")\n",
    "for i in range(len(queries)):\n",
    "#     cleaning each query\n",
    "    query = cleanQuery(queries[i])\n",
    "#     getting result from BM25 algorithm\n",
    "    result1 = brModel(query, main_dict, n_docs)\n",
    "    result2 = tfidf(n_docs, docs_nwords_list, main_dict, query)\n",
    "    result3 = BM25(0.75, 1.2, main_dict, docs_nwords_list, n_docs, query)\n",
    "\n",
    "    for j in range(10):\n",
    "        row1 = [queryIds[i], 1, result1[0][j], result1[1][j]]\n",
    "        BRM_result.append(row1)\n",
    "        row2 = [queryIds[i], 1, result2[0][j], result2[1][j]]\n",
    "        TFIDF_result.append(row2)\n",
    "        row3 = [queryIds[i], 1, result3[0][j], result3[1][j]]\n",
    "        BM25_result.append(row3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c3703",
   "metadata": {},
   "source": [
    "### Saving result of Boolean retreival model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9185d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(sys.path[0]+'/../Question_4/boolean.txt', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['QueryId', 'Iteration', 'DocId', 'Relevance'])\n",
    "writer.writerows(BRM_result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10521506",
   "metadata": {},
   "source": [
    "### Saving result of TFIDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ee3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(sys.path[0]+'/../Question_4/tfidf.txt', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['QueryId', 'Iteration', 'DocId', 'Relevance'])\n",
    "writer.writerows(TFIDF_result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97caae6a",
   "metadata": {},
   "source": [
    "### Saving result of BM25 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a0110dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(sys.path[0]+'/../Question_4/bm25.txt', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['QueryId', 'Iteration', 'DocId', 'Relevance'])\n",
    "writer.writerows(BM25_result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fb2ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been successfully created for all the models\n"
     ]
    }
   ],
   "source": [
    "print(\"Files have been successfully created for all the models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cf2ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(sys.path[0]+'/../Question_3/Ground_Truth.txt', 'w')\n",
    "# writer = csv.writer(f)\n",
    "# writer.writerow(['QueryId', 'Iteration', 'DocId', 'Relevance'])\n",
    "# writer.writerows(BM25_result)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9d136be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"QRelevance.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c33fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
